{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Same Generate Functions as Task 1"
      ],
      "metadata": {
        "id": "UIQb17m9PkfD"
      },
      "id": "UIQb17m9PkfD"
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "\n",
        "\n",
        "def generate_contents(chat_history):\n",
        "    \"\"\"\n",
        "    Converts a structured chat history and system instruction into Gemini-compatible contents.\n",
        "\n",
        "    Args:\n",
        "        chat_history (list): A list of dicts with keys 'role' and 'content'\n",
        "\n",
        "    Returns:\n",
        "        list[types.Content]: Gemini-compatible message sequence.\n",
        "    \"\"\"\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=entry[\"role\"],\n",
        "            parts=[types.Part.from_text(text=entry[\"content\"])]\n",
        "        ) for entry in chat_history\n",
        "    ]\n",
        "\n",
        "    return contents\n",
        "\n",
        "\n",
        "def generate(content, instructions,temp=0):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-02-c706fd6470f9\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  model = \"gemini-2.0-flash-001\" #Use flash because its fast\n",
        "  contents = content\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = temp, #0 Temp is better for classification\n",
        "    top_p = 1,\n",
        "    seed = 0,\n",
        "    max_output_tokens = 8192,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )],\n",
        "    system_instruction=[types.Part.from_text(text=instructions)],\n",
        "  )\n",
        "  response_text=\"\"\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    # print(chunk.text, end=\"\") #No need to print\n",
        "    response_text += chunk.text\n",
        "  return response_text.strip()"
      ],
      "metadata": {
        "id": "UX35wJKRPjrt"
      },
      "id": "UX35wJKRPjrt",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate User Question"
      ],
      "metadata": {
        "id": "sfos3BwSPsEq"
      },
      "id": "sfos3BwSPsEq"
    },
    {
      "cell_type": "code",
      "source": [
        "user_question_prompt1 = (\n",
        "        \"You are a classification assistant for civic technology services.\\n\"\n",
        "        \"Classify the following question into exactly one of the following categories:\\n\"\n",
        "        \"- Employment\\n- General Information\\n- Emergency Services\\n- Tax Related\\n\"\n",
        "        \"Respond ONLY with the category name.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "TUprNKYMR0oh"
      },
      "id": "TUprNKYMR0oh",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "urvbQVgGkOptTWTf57op7uTQ",
      "metadata": {
        "tags": [],
        "id": "urvbQVgGkOptTWTf57op7uTQ"
      },
      "source": [
        "def classify_user_question(question: str,system_instruction=user_question_prompt1) -> str:\n",
        "    \"\"\"\n",
        "    Classifies a user question into one of the predefined categories:\n",
        "    Employment, General Information, Emergency Services, or Tax Related.\n",
        "    \"\"\"\n",
        "    contents = generate_contents([{\"role\": \"user\", \"content\": question}])\n",
        "    return generate(contents, system_instruction)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the social Media post"
      ],
      "metadata": {
        "id": "Fq7FRAkOPzgQ"
      },
      "id": "Fq7FRAkOPzgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "social_post_prompt1 = (\n",
        "        \"You are a public information assistant. Generate a clear, informative, and professional social media post \"\n",
        "        \"for a government agency announcement. Keep it under 280 characters.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "uDsOb8qXR7r5"
      },
      "id": "uDsOb8qXR7r5",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_social_post(event_type: str, details: str,system_instruction=social_post_prompt1) -> str:\n",
        "    \"\"\"\n",
        "    Generates a short, professional social media post for a government announcement.\n",
        "    \"\"\"\n",
        "    prompt = f\"Event Type: {event_type}\\nDetails: {details}\"\n",
        "    contents = generate_contents([{\"role\": \"user\", \"content\": prompt}])\n",
        "    return generate(contents, system_instruction)\n"
      ],
      "metadata": {
        "id": "PJVkeEyEPv1L"
      },
      "id": "PJVkeEyEPv1L",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests Below"
      ],
      "metadata": {
        "id": "S-KlH1sUP7Lr"
      },
      "id": "S-KlH1sUP7Lr"
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "def compare_contents(output1: str, output2: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses Gemini to compare two pieces of content and determine if they are a close enough match.\n",
        "    Returns 'yes' or 'no'.\n",
        "    \"\"\"\n",
        "    system_instruction = (\n",
        "        \"You are a comparison assistant. Determine if the two outputs below are semantically similar \"\n",
        "        \"and express the same core meaning. Only respond with 'yes' or 'no'.\"\n",
        "    )\n",
        "\n",
        "    comparison_prompt = f\"\"\"\n",
        "Are the following two outputs similar enough in meaning?\n",
        "\n",
        "Output 1:\n",
        "{output1}\n",
        "\n",
        "Output 2:\n",
        "{output2}\n",
        "\n",
        "Only respond with 'yes' or 'no'.\n",
        "\"\"\"\n",
        "\n",
        "    contents = generate_contents([{\"role\": \"user\", \"content\": comparison_prompt}])\n",
        "    result = generate(contents, instructions=system_instruction).strip().lower()\n",
        "\n",
        "    # Normalize the response\n",
        "    if result.startswith(\"yes\"):\n",
        "        return \"yes\"\n",
        "    return \"no\"\n",
        "\n",
        "\n",
        "\n",
        "def test_classify_user_question():\n",
        "    category = classify_user_question(\"How do I apply for a government job?\")\n",
        "    assert category in [\"Employment\", \"General Information\", \"Emergency Services\", \"Tax Related\"] #Static Evaluation\n",
        "    print(\"Assert passed: \"+category)\n",
        "    comp=compare_contents(classify_user_question(\"How do I apply for a government job?\"), \"Employment\")\n",
        "    assert 'yes'==comp #GenAI Evaluation\n",
        "    print(\"Assert passed, category matched as expected\"+category)\n",
        "\n",
        "def test_generate_social_post():\n",
        "    post = generate_social_post(\"School Closing\", \"Schools will be closed due to snow on Friday.\")\n",
        "    assert len(post) < 300\n",
        "    print(\"Assert passed: \"+post)\n",
        "\n",
        "\n",
        "test_classify_user_question()\n",
        "test_generate_social_post()"
      ],
      "metadata": {
        "id": "kY5wfl6XP3Me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8fd2fe-8400-41eb-953f-fa36159def13"
      },
      "id": "kY5wfl6XP3Me",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assert passed: Employment\n",
            "yes\n",
            "Assert passed: ❄️ SCHOOL CLOSURE ALERT ❄️ All schools will be closed this Friday due to inclement weather. Stay safe and enjoy the snow! #SchoolClosure #SnowDay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation API Testing"
      ],
      "metadata": {
        "id": "sta10waqQYdy"
      },
      "id": "sta10waqQYdy"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from vertexai.preview.evaluation import EvalTask, MetricPromptTemplateExamples\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-02-c706fd6470f9\"\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "\n",
        "def generate_eval_data_for_classification(question: str, instructions: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Given a single user question and a list of instructions, generate a DataFrame\n",
        "    with Gemini responses to each instruction.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for instruction in instructions:\n",
        "        # You may need to update this line to match your existing generation logic\n",
        "        response = classify_user_question(question, system_instruction=instruction)\n",
        "\n",
        "        rows.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"context\": question,\n",
        "            \"response\": response\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "instructions = [\n",
        "    \"Classify this question into one of: Employment, General Information, Emergency Services, or Tax Related.\",\n",
        "    \"Look at this question and return one of: Employment, General Information, Emergency Services, or Tax Related. Please return just a value such as Employment, do not include any markdown or other info\",\n",
        "    \"Is this Employment, General Information, Emergency Services, or Tax Related?\"\n",
        "]\n",
        "\n",
        "question = \"How do I apply for a government job?\"\n",
        "\n",
        "eval_dataset = generate_eval_data_for_classification(question, instructions)\n",
        "\n",
        "eval_task = EvalTask(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=[\n",
        "        MetricPromptTemplateExamples.Pointwise.INSTRUCTION_FOLLOWING, #Check instruction following, required for instructions\n",
        "        MetricPromptTemplateExamples.Pointwise.TEXT_QUALITY, #Ensure text is high quality and not random\n",
        "        MetricPromptTemplateExamples.Pointwise.VERBOSITY, #Ensure responses are not verbose for this classification problem\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "prompt_template = (\n",
        "    \"Instruction: {instruction}\\n\"\n",
        "    \"Question: {context}\\n\"\n",
        "    \"Model classification: {response}\"\n",
        ")\n",
        "\n",
        "result = eval_task.evaluate(prompt_template=prompt_template)\n",
        "\n",
        "print(\"📊 Summary Metrics:\\n\")\n",
        "for key, value in result.summary_metrics.items():\n",
        "    print(f\"{key}: \\t{value}\")\n",
        "\n",
        "print(\"\\n📋 Detailed Table:\\n\")\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.expand_frame_repr\", False)\n",
        "\n",
        "# Show the table directly (not via print)\n",
        "print(result.metrics_table)\n",
        "prompt_template = (\n",
        "    \"Event type: {instruction}\\n\"\n",
        "    \"Details: {context}\\n\"\n",
        "    \"Generated Post: {response}\"\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RoL45TYjQCng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7af6d3a-2c10-4c0c-9da3-673160f5b7cb"
      },
      "id": "RoL45TYjQCng",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.preview.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Computing metrics with a total of 9 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 9/9 [00:08<00:00,  1.04it/s]\n",
            "INFO:vertexai.preview.evaluation._evaluation:All 9 metric requests are successfully computed.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Evaluation Took:8.69548723600019 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Summary Metrics:\n",
            "\n",
            "row_count: \t3\n",
            "instruction_following/mean: \t5.0\n",
            "instruction_following/std: \t0.0\n",
            "text_quality/mean: \t5.0\n",
            "text_quality/std: \t0.0\n",
            "verbosity/mean: \t0.0\n",
            "verbosity/std: \t0.0\n",
            "\n",
            "📋 Detailed Table:\n",
            "\n",
            "                                                                                                                                                                                              instruction                               context                         response                                                                                                                                                                                                                                                                                                 prompt                                                                                     instruction_following/explanation  instruction_following/score                                                                                                                                              text_quality/explanation  text_quality/score                                                                                                                                   verbosity/explanation  verbosity/score\n",
            "0                                                                                                Classify this question into one of: Employment, General Information, Emergency Services, or Tax Related.  How do I apply for a government job?                       Employment                                                                                                Instruction: Classify this question into one of: Employment, General Information, Emergency Services, or Tax Related.\\nQuestion: How do I apply for a government job?\\nModel classification: Employment             The model correctly classifies the question and follows the instructions by providing the classification.                          5.0  The response is exceptionally clear, coherent, and fluent, fully adhering to the instructions by accurately classifying the question into the 'Employment' category.                 5.0         The response is perfectly concise, providing the classification in a clear and succinct manner without any unnecessary wordiness or repetition.              0.0\n",
            "1  Look at this question and return one of: Employment, General Information, Emergency Services, or Tax Related. Please return just a value such as Employment, do not include any markdown or other info  How do I apply for a government job?                       Employment  Instruction: Look at this question and return one of: Employment, General Information, Emergency Services, or Tax Related. Please return just a value such as Employment, do not include any markdown or other info\\nQuestion: How do I apply for a government job?\\nModel classification: Employment  The model followed all instructions by selecting the right category and returning only the value with no extra info.                          5.0                       The model's response perfectly followed instructions by accurately classifying the question and providing the category in the requested format.                 5.0  The response is perfectly concise, providing all necessary information in a clear and succinct manner without any unnecessary wordiness or repetition.              0.0\n",
            "2                                                                                                                            Is this Employment, General Information, Emergency Services, or Tax Related?  How do I apply for a government job?  This is **Employment** related.                                                                                                       Instruction: Is this Employment, General Information, Emergency Services, or Tax Related?\\nQuestion: How do I apply for a government job?\\nModel classification: This is **Employment** related.           The response correctly identifies the category as Employment related, fulfilling the instruction perfectly.                          5.0       The model correctly reiterates the user's classification, indicating a complete understanding and adherence to the prompt's constraints and avoiding verbosity.                 5.0  The response is perfectly concise, providing all necessary information in a clear and succinct manner without any unnecessary wordiness or repetition.              0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-03-21d1fc6985f8 (May 12, 2025, 12:04:11 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}